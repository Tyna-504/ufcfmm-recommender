{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"top-of-page\"></a>\n",
    "# Table of Contents #\n",
    "Click on a chapter:<br>\n",
    "**[1. Training the model](#subtask3)<br>**\n",
    "**[2. Geolocation Segmentation](#2-geolocation-segmentation)<br>**\n",
    "[a. KNN](#2a-KNN)<br>\n",
    "[b. RFC](#2b-RFC)<br>\n",
    "[c. Conclusion](#2c-conclusion)<br>\n",
    "**[3. Collaborative Filtering](#3-collaborative-filtering)<br>**\n",
    "[a. Conclusion](#3a-conclusion)<br>\n",
    "**[4. Conclusion](#4_conclusion)<br>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Subtasks 3 and 4 are closely intertwined, with the former involving building the recommendation system and the latter involving evaluating its effectiveness using appropriate metrics. Performing these tasks together in one notebook allows for a more seamless and integrated approach to building and evaluating the recommendation system. This also makes it easier to keep track of the steps taken and results obtained and make any necessary changes or improvements. Additionally, since these tasks are shorter compared to Subtasks 1, 2, and 5, it makes sense to keep them together in one notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"subtask3\"></a>\n",
    "# 1. Subtask 3: Training the model\n",
    "\n",
    "To train the model, we will select features such as product price and review score and use the target variable of the product id as the prediction output.\n",
    "\n",
    "Firstly, we will create models using KNeighborsClassifer and RandomForestClassifier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import statements\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.neighbors import NearestNeighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the data from the CSV files\n",
    "orders = pd.read_csv('data/olist_orders_dataset.csv')\n",
    "order_items = pd.read_csv('data/olist_order_items_dataset.csv')\n",
    "products = pd.read_csv('data/olist_products_dataset.csv')\n",
    "reviews = pd.read_csv('data/olist_order_reviews_dataset.csv', encoding='ISO-8859-1')\n",
    "\n",
    "# merge the datasets to create a single DataFrame\n",
    "data = pd.merge(orders, order_items, on='order_id')\n",
    "data = pd.merge(data, products, on='product_id')\n",
    "data = pd.merge(data, reviews, on='order_id')\n",
    "\n",
    "# select the features and target variable\n",
    "X = data[['price', 'review_score']]\n",
    "y = data['product_id']\n",
    "\n",
    "# split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have prepared and split the data into train and test data, we can train the two models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier()"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create and train the model\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=4, n_estimators=10, n_jobs=-1)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc = RandomForestClassifier(n_estimators=10, n_jobs=-1, max_depth=4, verbose=0)\n",
    "rfc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"2-geolocation-segmentation\"></a>\n",
    "# 2. Subtask 4: Testing the model performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is crucial to evaluate the effectiveness of the recommender system to ensure that it is performing well and providing accurate recommendations to users. The metrics such as Area Under the Curve (AUC), precision, recall, f1, etc., are commonly used to evaluate the performance of recommendation systems.<br>\n",
    "\n",
    "However, the choice of evaluation metric should depend on the specific goals of the recommendation system and the type of data being used. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"2a-KNN\"></a>\n",
    "## a) KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is KNN and why are we using it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores for the KNN model\n",
      "Precision: 0.10767073321474538\n",
      "Recall: 0.12728877123317892\n",
      "f1: 0.10409291016884312\n"
     ]
    }
   ],
   "source": [
    "# make predictions on the testing data using the KNN model\n",
    "y_pred = knn.predict(X_test)\n",
    "\n",
    "# calculate precision, recall, f1-score, and AUC\n",
    "precision = precision_score(y_test, y_pred, average=\"weighted\")\n",
    "recall = recall_score(y_test, y_pred, average=\"weighted\")\n",
    "f1 = f1_score(y_test, y_pred, average=\"weighted\")\n",
    "# auc = roc_auc_score(y_test, y_pred)\n",
    "\n",
    "print(\"Scores for the KNN model\")\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"f1:\", f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"2b-RFC\"></a>\n",
    "## b) RFC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is RFC and why are we using it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores for the RFC model\n",
      "Precision: 0.002134507856317242\n",
      "Recall: 0.12728877123317892\n",
      "f1: 0.10409291016884312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# NOTE: JupyterHub kernel crashes due to the size of the data, therefore we have grabbed a small sample of test data.\n",
    "X_test_rfc = X_test.sample(frac=0.3, random_state=200)\n",
    "y_test_rfc = y_test.sample(frac=0.3, random_state=200)\n",
    "\n",
    "# make predictions on the testing data using the RFC model\n",
    "y_pred_rfc = rfc.predict(X_test_rfc)\n",
    "\n",
    "# calculate precision, recall, f1-score, and AUC\n",
    "precision = precision_score(y_test_rfc, y_pred_rfc, average=\"weighted\")\n",
    "# recall = recall_score(y_test, y_pred, average=\"weighted\")\n",
    "# f1 = f1_score(y_test, y_pred, average=\"weighted\")\n",
    "# auc = roc_auc_score(y_test, y_pred)\n",
    "\n",
    "print(\"Scores for the RFC model\")\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"f1:\", f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"2c-conclusion\"></a>\n",
    "## c) Conclusion\n",
    "<br>_[Go to top](#top-of-page)_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"3-collaborative-filtering\"></a>\n",
    "# 3. Subtask 3: Collaborative Filtering\n",
    "\n",
    "Collaborative filtering takes customers' previous orders and identifies patterns, and recommends products to customers based on previous customers' orders. If customer A orders products X and Y, then customer B who has ordered product X, will be recommended product Y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NearestNeighbors(algorithm='brute', metric='cosine')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in the data from the CSV files\n",
    "orders = pd.read_csv('data/olist_orders_dataset.csv')\n",
    "order_items = pd.read_csv('data/olist_order_items_dataset.csv')\n",
    "products = pd.read_csv('data/olist_products_dataset.csv')\n",
    "reviews = pd.read_csv('data/olist_order_reviews_dataset.csv', encoding='ISO-8859-1')\n",
    "\n",
    "# merge the datasets to create a single DataFrame\n",
    "data = pd.merge(orders, order_items, on='order_id')\n",
    "data = pd.merge(data, products, on='product_id')\n",
    "data = pd.merge(data, reviews, on='order_id')\n",
    "\n",
    "\n",
    "# filter the data to include only the most active customers\n",
    "# NOTE: this is mainly done due to performance issues.\n",
    "customer_counts = data['customer_id'].value_counts()\n",
    "active_customers = customer_counts[customer_counts > 3].index\n",
    "data = data[data['customer_id'].isin(active_customers)]\n",
    "\n",
    "\n",
    "# split the data into training and testing sets\n",
    "train_data, test_data = train_test_split(data, test_size=0.2)\n",
    "\n",
    "# create a pivot table with customers as rows and products as columns using the training data\n",
    "pivot = train_data.pivot_table(index='customer_id', columns='product_id', values='review_score')\n",
    "\n",
    "# fill missing values with 0\n",
    "pivot = pivot.fillna(0)\n",
    "\n",
    "# convert the pivot table to a sparse matrix\n",
    "matrix = csr_matrix(pivot.values)\n",
    "\n",
    "# create and fit a NearestNeighbors model using the training data\n",
    "model = NearestNeighbors(metric='cosine', algorithm='brute')\n",
    "model.fit(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to recommend products for a given customer\n",
    "def recommend_products(customer_id):\n",
    "    # find the index of the customer in the pivot table\n",
    "    customer_index = pivot.index.get_loc(customer_id)\n",
    "    \n",
    "    # find the k nearest neighbors of the customer\n",
    "    distances, indices = model.kneighbors(pivot.iloc[customer_index, :].values.reshape(1, -1), n_neighbors=6)\n",
    "    \n",
    "    # get the product ids of the products purchased by the nearest neighbors\n",
    "    product_ids = []\n",
    "    for i in range(0, len(distances.flatten())):\n",
    "        if i == 0:\n",
    "            continue\n",
    "        else:\n",
    "#             product_ids.extend(pivot.index[indices.flatten()[i]])\n",
    "            # append the recommended product ID to the array.\n",
    "            product_ids.append(pivot.columns[indices.flatten()[i]])\n",
    "    \n",
    "    # return the most common product ids\n",
    "    return pd.Series(product_ids).value_counts().head().index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['35afc973633aaeb6b877ff57b2793310', '98d61056e0568ba048e5d78038790e77', '8b8422bfeaebcd02e897666185ca2c2c', '8bb27b1d96be90b36b8d0c7f30931d52', '8b45810da2ef9860496d56f62435fc40']\n"
     ]
    }
   ],
   "source": [
    "# test the recommend_products function on a customer from the testing data.\n",
    "test_customer = test_data.iloc[0]['customer_id']\n",
    "recommended_products = recommend_products(test_customer)\n",
    "print(recommended_products)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"3a-conclusion\"></a>\n",
    "## a) Conclusion\n",
    "\n",
    "The KNN and RFM models are low in performance quality. They are only 10% -13 % accurate and precise.\n",
    "\n",
    "Collaborative Filtering seems to be more appropriate for this scenario.\n",
    "<br>_[Go to top](#top-of-page)_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"4_conclusion\"></a>\n",
    "# 4. Subtask 3 & 4: Conclusion\n",
    "Key takeaways and how it informs what we do next?\n",
    "<br>_[Go to top](#top-of-page)_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "End of subtask 3 and 4"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DMenv",
   "language": "python",
   "name": "dmenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
